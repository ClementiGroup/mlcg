model:
  loss:
    class_path: mlcg.nn.Loss
    init_args:
      losses:
        - class_path: mlcg.nn.ForceMSE
          init_args:
            force_kwd: forces
  model:
    class_path: mlcg.nn.tmdnet_interface.TorchMDNetInterface
    init_args:
      hparams:
        # model to use; any of graph-network, transformer, equivariant-transformer
        model: equivariant-transformer

        # RBF & cutoff parameters
        # either gauss or expnorm
        rbf_type: expnorm
        num_rbf: 64
        trainable_rbf: false
        cutoff_lower: 0.0
        cutoff_upper: 15.0

        # ET specific parameter
        # any of "keys", "values", "both", "none"
        distance_influence: both
        # Number of attention heads
        num_heads: 16

        # SHARED parameters
        embedding_dimension: 128
        # NL buffer arg
        max_z: 50
        max_num_neighbors: 300
        # Whether to perform an initial neighbor embedding step.
        neighbor_embedding: true
        # The number of attention layers
        num_layers: 2

        # activation function parameters
        # can be any of ssp, silu, tanh, sigmoid
        # to use in the output MLP
        activation: tanh
        # to use in the model
        attn_activation: tanh

        # dump of parameters that should not be changed
        derivative: true
        atom_filter: -1
        # message passing aggregation function
        aggr: add
        # type of output MLP; either Scalar or EquivariantScalar
        output_model: Scalar
        # reduction type in the output MLP
        reduce_op: add

