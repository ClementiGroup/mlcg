seed_everything: 16384
ckpt_path: null
trainer:
  benchmark: false
  callbacks:
    - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
      init_args:
        dirpath: default_root_dir
        filename: '{epoch}-{validation_loss:.4f}'
        monitor: validation_loss
        save_last: true
        save_top_k: -1
  default_root_dir: .
  detect_anomaly: false
  deterministic: false
  enable_checkpointing: true
  enable_progress_bar: false
  strategy: 'ddp_find_unused_parameters_false'
  accelerator: gpu
  devices: 4
  precision: 32
  logger:
  - class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      name: tensorboard
      save_dir: default_root_dir
      version: ''
  max_epochs: 550
  plugins: null
  reload_dataloaders_every_n_epochs: 0
model:
  loss:
    class_path: mlcg.nn.Loss
    init_args:
      losses:
      - class_path: mlcg.nn.ForceMSE
        init_args:
          force_kwd: forces
  model:
    class_path: mlcg.nn.GradientsOut
    init_args:
      model:
        class_path: mlcg.nn.schnet.AttentiveSchNet
        init_args:
          activation_func:
            class_path: torch.nn.Tanh
            init_args: {}
          aggr: add
          cutoff:
            class_path: mlcg.nn.CosineCutoff
            init_args:
              cutoff_lower: 0
              cutoff_upper: 30
          embedding_size: 43
          hidden_channels: 128
          max_num_neighbors: 200
          num_filters: 128
          attention_block:
            class_path: mlcg.nn.ExactAttention
          num_interactions: 1
          num_features_in: 128
          num_features_out: 128
          num_residual_k: 1
          num_residual_q: 1
          num_residual_v: 1
          output_hidden_layer_widths:
          - 32
          - 16
          rbf_layer:
            class_path: mlcg.nn.ExpNormalBasis
            init_args:
              cutoff: 30
              num_rbf: 128
              trainable: false
      targets: forces
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.0001
data:
  dataset:
    class_path: mlcg.datasets.ChignolinDataset
    init_args:
      root: /path/to/save/dataset/
  log_dir: default_root_dir
  val_ratio: 0.1
  test_ratio: 0.
  batch_size: 256
  inference_batch_size: 256
  num_workers: 0
  loading_stride: 1
  save_local_copy: false