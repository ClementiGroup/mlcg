{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0f52c9",
   "metadata": {},
   "source": [
    "# Building a CG Model of the Miniprotein Chignolin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f512e6",
   "metadata": {},
   "source": [
    "Chignolin is a miniprotein that is ten amino acids long. The variant CLN025 in particular shows three metastable molecular states, corresponding to folded, misfolded, and unfolded conformations. To build a CG force field for coarse grain molecular dynamics through force matching, we must first download and prepare a dataset in order to train our neural network. The dataset that we choose is composed of 3744 all-atom simulations of CLN025 at 350K using CHARMM22* via an adaptive sampling strategy. The data is publicly available at http://pub.htmd.org/chignolin_trajectories.tar.gz .\n",
    "\n",
    "For convenience, we have provided an example `torch_geometric.data.InMemoryDataset` class that automatically downloads, unzips, and organizes the data. Once the data is organized, the all-atom\n",
    "coordinates and forces are mapped to a 10 bead carbon alpha coarse grained representation. Using the mapped coordinate data, a baseline prior model according to [CGSchNet](https://doi.org/10.1063/5.0026133) is parametetrized\n",
    "and used to subtract baseline coarse grain forces from the total coarse grain forces. The resulting \"delta forces\" can then be used as supervised learning targets for training coarse grain force\n",
    "field models through force matching.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823b916",
   "metadata": {},
   "source": [
    "## Loading the CLN025 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3541a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../../\")\n",
    "from mlcg.datasets import ChignolinDataset\n",
    "from mlcg.pl import merge_priors_and_checkpoint\n",
    "from mlcg.utils import load_yaml, dump_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026c9ed",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672297ba",
   "metadata": {},
   "source": [
    "To download and process the data, we supply a path when instantiating the dataset. The coordinates, forces, topology, and other important information will be organized and stored in this directory. In total, the raw (all-atom) dataset is about ~14 GB, while the CG dataset only occupies about ~1.2 GB in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"PATH/TO/STORE/THE/DATASET\"\n",
    "root = \"/net/data02/nickc/mlcg_cln\"\n",
    "dataset = ChignolinDataset(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998b08a",
   "metadata": {},
   "source": [
    "With the dataset downloaded and processed, we can take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77086a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CG mapped data:\\n\\n\", dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfba7c5",
   "metadata": {},
   "source": [
    "Altogether, we have an aggregate ~1.8M frames of trajectory data (for both coordinates and forces). The collated data also contains information about the masses and the neighborlists associated with the features of the baseline/prior model (see below). We can also visualize how the different CG beads are typed. `mlcg.geometry.topology` contains several useful tools for graph related operations. Here, we use `get_connectivity_matrix` to generate a connectivity/adjacency matrix associated with the bonded structure of our CG mapping of Chignolin. This matrix can be used directly with `networkx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c903ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "dataset.topologies.draw(\n",
    "    layout_kwargs={\"seed\": 7},\n",
    "    drawing_kwargs={\n",
    "        \"node_size\": 3000,\n",
    "        \"width\": 5,\n",
    "        \"edgecolors\": \"black\",\n",
    "        \"ax\": ax,\n",
    "        \"linewidths\": 5,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e6e4a",
   "metadata": {},
   "source": [
    "Here, we see that integer type have been assigned to each of the 10 carbon alpha atoms according to its amino acid identity, while allocating special types for the terminal TYR1 and TYR10 carbon alpha atoms. Because Pytorch Geometric is built upon `networkx`, there are several other graph analysis functions that are of general use in the `mlcg.geometry.topology` module. We can also inspect the baseline model that produced the delta forces that will be used for training the model describing the CG forcefeild:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee74281",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.prior_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbcccf",
   "metadata": {},
   "source": [
    "We see that our baseline model contains three prior types, which are defined in `mlcg.nn.prior`: `HarmonicBonds` to constrain sequential carbon alpha pairs and `HarmonicAngles` to constrain sequential carbon alpha triplets along the molecular backbone. These two priors keep the CG molecule from breaking apart or becoming too flexible. The baseline model also employs a `Repulsion` prior to all non-bonded carbon alpha atoms, which helps to prevent distant parts of the CG molecule from overlapping or collapsing on itself. When an `AtomicData` instance is forwarded through a prior, it must contain information in the `neighborlist` attribute so that the corresponding features (eg, distances or angles) can be computed from the coordinates (for more on this, see the simulation section below!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afd7a5",
   "metadata": {},
   "source": [
    "# Training a Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39414e2",
   "metadata": {},
   "source": [
    "With the dataset downloaded and processed, we can now build and train a model to predict CG forces and energies. For our model, we choose CGSchNet, based on [CGSchNet](https://doi.org/10.1063/5.0026133). CGSchNet is an extended version of the SchNet graph neural network architecture for CG molecular systems. It accepts coordinates (specifically pairwise distances) and CG atom types as model inputs, and predicts CG energies and cartesian forces that can later be used for generative CG simulation. \n",
    "\n",
    "To train the model, normally, we use PyTorch Lightning CLI, which removes training boiler plate code/scripts by using training and model parameters specified entirely in a configuration `YAML` file. If users wish to make more general models, or if they prefer to implement their own training routines, all neural network and prior utilities are contained in the `mlcg.nn` subpackage. Here, we explicitly build a model from scratch to showcase both structure and flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfebd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory used to save training informations\n",
    "TRAIN_PATH = osp.abspath(\"./train/\")\n",
    "!mkdir $TRAIN_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f39c0d",
   "metadata": {},
   "source": [
    "## Training in the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d692c54",
   "metadata": {},
   "source": [
    "### radial basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db940c",
   "metadata": {},
   "source": [
    "For a SchNet model, we must first choose our Radial basis and Cutoff functions for the filter generating network. For this example, we choose `ExpNormalBasis` based on the PhysNet-style RBFs introduced in [Physnet](https://doi.org/10.1021/acs.jctc.9b00181). Since this basis already contains a `CosineCutoff` envelope, we simply use `IdentityCutoff` for our cutoff function. We can directly visualize our basis using tools from `mlcg.nn.radial_basis`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcg.nn.radial_basis import ExpNormalBasis, visualize_basis\n",
    "from mlcg.nn.cutoff import IdentityCutoff\n",
    "\n",
    "cutoff_lower = 0.00\n",
    "cutoff_upper = 20.00\n",
    "num_rbf = 64\n",
    "\n",
    "cutoff_fn = IdentityCutoff(cutoff_lower=cutoff_lower, cutoff_upper=cutoff_upper)\n",
    "rbf_layer = ExpNormalBasis(cutoff=cutoff_upper, num_rbf=64)\n",
    "visualize_basis(rbf_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c95a3",
   "metadata": {},
   "source": [
    "### SchNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb2d21",
   "metadata": {},
   "source": [
    "We can see that our basis offers higher filter resolution at smaller distances, while larger distances the filter resolution is more broad and the natural response is weaker. Next, we are ready to make our full SchNet enegy model. Although we have the freedom to assemble more modular constructions through the use of the `SchNet` class, we will instead use a convenient subclass called `StandardSchNet` that only requires the user to supply a cutoff and an RBF layer. The remaining options can be specified through keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcg.nn import StandardSchNet\n",
    "\n",
    "schnet_params = {\n",
    "    \"max_num_neighbors\": 50,\n",
    "    \"embedding_size\": 44,\n",
    "    \"num_interactions\": 3,\n",
    "    \"num_filters\": 128,\n",
    "    \"hidden_channels\": 128,\n",
    "    \"output_hidden_layer_widths\": [128, 128],\n",
    "    \"activation\": torch.nn.Tanh(),\n",
    "    \"aggr\": \"add\",\n",
    "}\n",
    "\n",
    "energy_model = StandardSchNet(rbf_layer, cutoff_fn, **schnet_params)\n",
    "print(energy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb12b7e",
   "metadata": {},
   "source": [
    "Our SchNet model can predict scalar energies for each example/structure passsed to it in a batch of data. These energies are stored in the `out` field of an `AtomicData` instance that passes through the energy model. In this way, it is natural to think of models as objects that update `AtomicData` instances (by populating them with new attributes/predictions). However, to train our model using force matching we must extract CG forces from the predicted CG energies through a gradient operation. To achieve this, we wrap our SchNet model with a `GradientsOut` object. `GradientsOut` simply requires an energy model and a list of prediction targets that can be acquired through gradient operations. In this case, we specify our gradient wrapper to calculate the CG forces. In pricple, any model can be wrapped by any operation, as data outputs are always stored in `AtomicData.out`, so it is possible to retreive higher order gradients or transform the energy into other physical properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcg.nn.gradients import GradientsOut\n",
    "\n",
    "full_model = GradientsOut(energy_model, targets=[\"forces\"])\n",
    "print(full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df926566",
   "metadata": {},
   "source": [
    "### Setting up the actual training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a59a2",
   "metadata": {},
   "source": [
    "Next, to train our model, we can use Pytorch Lighning utilities `PLModel` and `DataModule`, which handle optimization of the model parameters and migration of data from the dataset to the model respectively. The former requires a loss function and a pytorch optimizer class path. For the loss function, we choose `ForceRMSE`, which reports the root-mean-square error between predicted CG forces and reference forces. The `DataModule` accepts our Chignolin dataset instanced above. In order to save time, we stride the training data by a factor of 1000 (though this will obviously result in reduced accuracy in the trained model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7aefe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from mlcg.nn.losses import ForceRMSE\n",
    "from mlcg.pl import PLModel, DataModule\n",
    "\n",
    "loss_fn = ForceRMSE(\"forces\")\n",
    "pl.seed_everything(12659843)\n",
    "optimizer_dict = {\"class_path\": \"torch.optim.Adam\", \"init_args\": {\"lr\": 5e-4}}\n",
    "lr_scheduler = {\n",
    "    \"class_path\": \"torch.optim.lr_scheduler.ReduceLROnPlateau\",\n",
    "    \"init_args\": {\n",
    "        \"factor\": 0.9,\n",
    "        \"patience\": 10,\n",
    "        \"min_lr\": 1e-5,\n",
    "    },\n",
    "}\n",
    "plmodel = PLModel(full_model, loss_fn, optimizer_dict, lr_scheduler)\n",
    "dm = DataModule(dataset, log_dir=TRAIN_PATH, loading_stride=1000, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266ece4",
   "metadata": {},
   "source": [
    "We can now combine our `PLModel` and `DataModule` by using the Pytorch Lightning `Trainer` object. `Trainer`can be supplied with callbacks, schedulers, etc. The `Trainer` can also take advantage of useful logging tools such as TensorBoard (or several other third party loggers). For this example, we choose to train only using the CPU, but it is very simple to specify GPU training by chaning the accelerator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=TRAIN_PATH,\n",
    "    monitor=\"validation_loss\",\n",
    "    save_top_k=-1,  # -1 to save all\n",
    "    every_n_epochs=1,\n",
    "    filename=\"{epoch}-{validation_loss:.4f}\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"validation_loss\", patience=10, min_delta=5e-2\n",
    ")\n",
    "tb_logger = pl.loggers.TensorBoardLogger(\n",
    "    TRAIN_PATH, name=\"tensorboard\", version=\"\"\n",
    ")\n",
    "csv_logger = pl.loggers.CSVLogger(TRAIN_PATH, name=\"\", version=\"\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    precision=32,\n",
    "    auto_lr_find=False,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, early_stopping],\n",
    "    logger=[tb_logger, csv_logger],\n",
    "    log_every_n_steps=1,\n",
    "    reload_dataloaders_every_epoch=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05edf8",
   "metadata": {},
   "source": [
    "We can begin training our model by calling the `Trainer.fit()` method and supplying our `PLModel` and `DataModule`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dd3fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import ctime\n",
    "\n",
    "print(f\"Starting training at {ctime()}\")\n",
    "trainer.fit(plmodel, dm)\n",
    "print(f\"Ending training at {ctime()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8fb6d",
   "metadata": {},
   "source": [
    "## Through the CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c12257",
   "metadata": {},
   "source": [
    "A typical input file to train a Schnet model looks like below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../inputs/train_schnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6ec76",
   "metadata": {},
   "source": [
    "The fields **trainer.default_root_dir** and **data.dataset.root** need to be adapted to your environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde2aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml(\"../inputs/train_schnet.yaml\")\n",
    "config[\"trainer\"][\"default_root_dir\"] = TRAIN_PATH\n",
    "config[\"data\"][\"dataset\"][\"init_args\"][\"root\"] = osp.abspath(root)\n",
    "train_fn = osp.join(TRAIN_PATH, \"train.yaml\")\n",
    "dump_yaml(train_fn, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28135730",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../../scripts/mlcg-train.py fit --config $train_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ece774",
   "metadata": {},
   "source": [
    "## Monitor the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c4a62",
   "metadata": {},
   "source": [
    "After the training has finished, we can inspect the results according to our specified metrics. If you are familiar with Tensorboard you can run `tensorboard --logdir (PATH_TO_TENSORBOARD_LOGS)` and navigate to the corresponding localhost using your browser (if you are running the notebook remotely, listen for the port on you local machine via `ssh -NL PORT:localhost:PORT user@remote`). Althernatively, you may use `pandas` to load the `metrics.csv` file saved by the `Trainer` in the training directory. Because we have such an agressive data stride, we can see that the model quickly overfits (as evidenced by the curvature change in the validation loss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f86e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = pd.read_csv(\"train/metrics.csv\")\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# Here, we only are interested in the epochal train/validation losses,\n",
    "# so we must filter the other non-epochal enetries in the logfile, which\n",
    "# are recorded as NaNs\n",
    "train_loss = metrics[\"training_loss_epoch\"].to_numpy()\n",
    "nan_idx = np.isnan(train_loss)\n",
    "no_nan_idx = ~nan_idx\n",
    "train_loss = train_loss[no_nan_idx]\n",
    "\n",
    "val_loss = metrics[\"validation_loss_epoch\"].to_numpy()\n",
    "nan_idx = np.isnan(val_loss)\n",
    "no_nan_idx = ~nan_idx\n",
    "val_loss = val_loss[no_nan_idx]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.ylabel(\"Loss (kcal/mol/angstrom)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665c8fb",
   "metadata": {},
   "source": [
    "There are other useful files produced by the training routine. The first to note are are `ckpt` checkpoint files, which record the state of the model at the corresponding epoch. These can be reloaded for a continued or (possibly) different training routine at a future time. The second important file is `hparams.yaml`, which is a YAML file that stores the information about the hyperparemeters used to instantiate the model, the loss function, and the training routine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3349c",
   "metadata": {},
   "source": [
    "# Using a Trained Model as a CG Force Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150b5cb",
   "metadata": {},
   "source": [
    "With our model trained, we can use its ability to predict forces as a component of a CG molecular dynamics simulation. Currently, we implement Langevin and overdamped Langevin simulation schemes - here we will test the practical performance of our trained model using a Langevin simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb56f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_PATH = osp.abspath(\"./simulate/\")\n",
    "\n",
    "input_config_fn = osp.join(SIM_PATH, \"input_configurations.pt\")\n",
    "model_fn = osp.join(SIM_PATH, \"model.pt\")\n",
    "\n",
    "!mkdir $SIM_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c5103",
   "metadata": {},
   "source": [
    "## Setup the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37b26b",
   "metadata": {},
   "source": [
    "### Input configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e822ea0",
   "metadata": {},
   "source": [
    "Once the simulation has been set up, we must pass it a list of `AtomicData` containing the initial coordinates, atom types, and masses. For this demonstration, we select 10 random frames from the entire dataset. As mentioned in the beginning of this notebook, the prior CG forces were subtracted away from the full CG forces in order to train the network on the delta CG forces. In order to simulate physically meaningful results, our network model needs to be combined with the original priors to create the full force field - meaning we must make sure to supply our `AtomicData`s with the poper neighbor list for each prior so that features, such as bonds or angles, may be computed properly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_nls = {}\n",
    "for model in dataset.priors_cls:\n",
    "    prior_nls.update(**model.neighbor_list(dataset.topologies))\n",
    "\n",
    "full_idx = np.arange(len(dataset))\n",
    "chosen_idx = np.random.choice(full_idx, 10)\n",
    "\n",
    "initial_data_list = []\n",
    "for idx in chosen_idx:\n",
    "    data = dataset.get(idx)\n",
    "    data.neighbor_list = prior_nls\n",
    "    initial_data_list.append(data)\n",
    "print(initial_data_list[0])\n",
    "\n",
    "torch.save(initial_data_list, input_config_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3225f2",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4503e51",
   "metadata": {},
   "source": [
    "To combine our network and prior models, we can use the `SumOut` class defined in `mlcg.nn.gradients`. `SumOut` aggregates the properties predicted in `AtomicData.out` over multiple models, allowing for multiple force terms that maybe represented by several networks or prior models. For simplicity, we use a helper method from `mlcg.pl` to produce our final model for simulation. In principle, `SumOut` can be used to combine arbitrary models together - once again taking advantage of the fact that the output of each model is stored individually in `AtomicData.out` by model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcg.pl import merge_priors_and_checkpoint\n",
    "\n",
    "try:\n",
    "    model = merge_priors_and_checkpoint(\"train/last.ckpt\", dataset.prior_models)\n",
    "except FileNotFoundError:\n",
    "    model = merge_priors_and_checkpoint(\n",
    "        \"train/ckpt/last.ckpt\", dataset.prior_models\n",
    "    )\n",
    "print(model)\n",
    "\n",
    "torch.save(model, model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09552f0a",
   "metadata": {},
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a1e41",
   "metadata": {},
   "source": [
    "With the model and the initial configurations prepared, we are ready to run CG simulations. We choose the LangevinSimulation class defined in `mlcg.simulation`, for which we are free to adjust the inverse temperature, the integration timestep, etc. As with the training we can prepare the simulation explicitly or with the use CLI tools:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf0372",
   "metadata": {},
   "source": [
    "### In the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af208e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcg.simulation import LangevinSimulation\n",
    "\n",
    "n_timesteps = 10000\n",
    "save_interval = 10\n",
    "export_interval = 1000\n",
    "log_interval = 1000\n",
    "dt = 0.004\n",
    "friction = 1.0\n",
    "beta = dataset.beta\n",
    "filename = \"simulate/cln_model\"\n",
    "\n",
    "simulation = LangevinSimulation(\n",
    "    friction,\n",
    "    dt=dt,\n",
    "    beta=beta,\n",
    "    n_timesteps=n_timesteps,\n",
    "    save_interval=save_interval,\n",
    "    export_interval=export_interval,\n",
    "    log_interval=log_interval,\n",
    "    filename=filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.attach_configurations(initial_data_list)\n",
    "simulation.attach_model(model)\n",
    "\n",
    "print(f\"Starting simulation at {ctime()}\")\n",
    "cg_traj = simulation.simulate()\n",
    "print(f\"Ending simulation at {ctime()}\")\n",
    "print(\"simulation output:\", cg_traj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58e8b5",
   "metadata": {},
   "source": [
    "We see that our output has a shape `(n_sims, n_saved_configurations, n_atoms, 3)`.With the training complete, our CG trajectory is ready for analysis via MDTraj or PyEmma tools. We suggest following the tutorials [Here](http://www.emma-project.org/latest/tutorials/notebooks/00-pentapeptide-showcase.html) for analyzing free energy surfaces for high dimensional systems. Instead, here we will simply inspect the CG trajectories using the NGLView plugin, which allows for simple molecular movie generation within a Jupyter notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc02e1",
   "metadata": {},
   "source": [
    "### With the CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b97b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A typical simulation input file\n",
    "!cat ../inputs/langevin.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which need to be adapted to your configuration\n",
    "config = load_yaml(\"../inputs/langevin.yaml\")\n",
    "config[\"model_file\"] = model_fn\n",
    "config[\"structure_file\"] = input_config_fn\n",
    "config[\"simulation\"][\"filename\"] = osp.join(SIM_PATH, \"cln_model_cli\")\n",
    "\n",
    "config_fn = osp.join(SIM_PATH, \"simulate.yaml\")\n",
    "dump_yaml(config_fn, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b109c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../../scripts/mlcg-nvt_langevin.py --config $config_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa862e",
   "metadata": {},
   "source": [
    "# Look at the trajectories\n",
    "\n",
    "Lastly, we can look at each of the trajectories using the NGLview Jupyter notebook plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22031327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview as nv\n",
    "from glob import glob\n",
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_traj_fns = sorted(glob(\"simulate/*_coords_*\"))\n",
    "cg_trajs = [np.load(fn) for fn in cg_traj_fns]\n",
    "cg_trajs = np.concatenate(cg_trajs, axis=1)\n",
    "print(\"CG trajectories:\", cg_trajs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if NGLview complains, you may need to update it or ask for a proper CG chignolin PDB file.\n",
    "# Alternatively, you can reduce the pdb stored in the processed subdirectory of the data directory\n",
    "\n",
    "mdtraj_topo = dataset.topologies.to_mdtraj()\n",
    "chosen_trajectory = 0\n",
    "cg_traj = md.Trajectory(\n",
    "    cg_trajs[chosen_trajectory, :, :, :] / 10.0, mdtraj_topo\n",
    ")  # divide by 10 to match the natural units of nm in NGLView\n",
    "print(cg_traj)\n",
    "cg_traj.superpose(cg_traj, frame=0)\n",
    "\n",
    "t = nv.MDTrajTrajectory(cg_traj)\n",
    "w = nv.NGLWidget(t)\n",
    "w.parameters = {\"backgroundColor\": \"white\", \"representation\": \"backbone\"}\n",
    "w.add_representation(\"licorice\")\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46eebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "527ea2ca627c63b749937ceb479d8cbab2a946f20c5dd6047d977cc7be213261"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
