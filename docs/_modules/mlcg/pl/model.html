<!DOCTYPE html>
<html lang="en" data-accent-color="plum" data-content_root="../../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>mlcg.pl.model - mlcg 0.1.2 documentation</title><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=31853864" />
    <link rel="stylesheet" type="text/css" href="../../../_static/shibuya.css?v=44020203" />
    <link media="print" rel="stylesheet" type="text/css" href="../../../_static/print.css?v=20ff2c19" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="mlcg.pl.model"/>
    <meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../../index.html">
      
      
      <strong>mlcg</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../data/index.html">Data and datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../data/atom_data.html">Molecular Data Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../data/fixed_datasets.html">Fixed datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../data/h5_datasets.html">H5 Dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../geometry/index.html">Geometry and Neighbor lists</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../geometry/internal_coordinates.html">Internal Coordinate Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../geometry/neighbor_list.html">Neighbor Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../geometry/topology.html">Topology Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../geometry/statistics.html">Statistics Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/index.html">Model utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../models/priors.html">Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/cutoffs.html">Cutoff Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/rbfs.html">Radial Basis Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/mlip.html">MLIPs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/wrappers.html">Gradient/sum wrappers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../models/losses.html">Loss Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../simulation/index.html">Simulations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../simulation/langevin.html">Langevin Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../simulation/overdamped.html">Overdamped Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../simulation/parallel_tempering.html">Parallel Tempering Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../simulation/utils.html">Simulation utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../misc/index.html">Miscellaneous utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../misc/coarse_graining.html">Coarse Graining</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../misc/utils.html">General utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../misc/mol_utils.html">Molecular utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../dev/index.html">Developer Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dev/doc.html">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../dev/tests.html">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bibliography.html">Bibliography</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../../index.html"><span itemprop="name">mlcg</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Module code</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">mlcg.pl.model</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="relative min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
  <article class="yue" role="main">
          <h1>Source code for mlcg.pl.model</h1><div class="highlight"><pre>
<span></span><span data-line="1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span data-line="2"><span class="kn">import</span><span class="w"> </span><span class="nn">pytorch_lightning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
</span><span data-line="3"><span class="kn">from</span><span class="w"> </span><span class="nn">..utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">detect_nan_parameters</span>
</span><span data-line="4"><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tuple</span>
</span><span data-line="5"><span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
</span><span data-line="6">
</span><span data-line="7"><span class="kn">from</span><span class="w"> </span><span class="nn">..data</span><span class="w"> </span><span class="kn">import</span> <span class="n">AtomicData</span>
</span><span data-line="8"><span class="kn">from</span><span class="w"> </span><span class="nn">..data._keys</span><span class="w"> </span><span class="kn">import</span> <span class="n">N_ATOMS_KEY</span>
</span><span data-line="9"><span class="kn">from</span><span class="w"> </span><span class="nn">..nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Loss</span><span class="p">,</span> <span class="n">GradientsOut</span>
</span><span data-line="10">
</span><span data-line="11">
</span><span data-line="12"><span class="k">def</span><span class="w"> </span><span class="nf">get_class_from_str</span><span class="p">(</span><span class="n">class_path</span><span class="p">):</span>
</span><span data-line="13">    <span class="n">class_module</span><span class="p">,</span> <span class="n">class_name</span> <span class="o">=</span> <span class="n">class_path</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="14">    <span class="n">module</span> <span class="o">=</span> <span class="nb">__import__</span><span class="p">(</span><span class="n">class_module</span><span class="p">,</span> <span class="n">fromlist</span><span class="o">=</span><span class="p">[</span><span class="n">class_name</span><span class="p">])</span>
</span><span data-line="15">    <span class="n">args_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">class_name</span><span class="p">)</span>
</span><span data-line="16">    <span class="k">return</span> <span class="n">args_class</span>
</span><span data-line="17">
</span><span data-line="18">
<div class="viewcode-block" id="PLModel">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel">[docs]</a>
</span><span data-line="19"><span class="k">class</span><span class="w"> </span><span class="nc">PLModel</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
</span><span data-line="20"><span class="w">    </span><span class="sd">&quot;&quot;&quot;PL interface to train with models defined in :ref:`mlcg.nn`.</span>
</span><span data-line="21">
</span><span data-line="22"><span class="sd">    Parameters</span>
</span><span data-line="23"><span class="sd">    ----------</span>
</span><span data-line="24">
</span><span data-line="25"><span class="sd">        model:</span>
</span><span data-line="26"><span class="sd">            instance of a model class from :ref:`mlcg.nn`.</span>
</span><span data-line="27"><span class="sd">        loss:</span>
</span><span data-line="28"><span class="sd">            instance of :ref:`mlcg.nn.Loss`.</span>
</span><span data-line="29"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="30">
</span><span data-line="31">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="32">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="33">        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span><span data-line="34">        <span class="n">loss</span><span class="p">:</span> <span class="n">Loss</span><span class="p">,</span>
</span><span data-line="35">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="36"><span class="w">        </span><span class="sd">&quot;&quot;&quot; &quot;&quot;&quot;</span>
</span><span data-line="37">
</span><span data-line="38">        <span class="nb">super</span><span class="p">(</span><span class="n">PLModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span data-line="39">
</span><span data-line="40">        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">logger</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span data-line="41">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span data-line="42">        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
</span><span data-line="43">        <span class="bp">self</span><span class="o">.</span><span class="n">validation_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span data-line="44">
</span><span data-line="45">        <span class="bp">self</span><span class="o">.</span><span class="n">derivative</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;derivative&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span data-line="46">        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
</span><span data-line="47">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">GradientsOut</span><span class="p">):</span>
</span><span data-line="48">                <span class="bp">self</span><span class="o">.</span><span class="n">derivative</span> <span class="o">=</span> <span class="kc">True</span>
</span><span data-line="49">
<div class="viewcode-block" id="PLModel.on_train_epoch_start">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel.on_train_epoch_start">[docs]</a>
</span><span data-line="50">    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span data-line="51">        <span class="c1"># this can avoid growing VRAM usage after 1 epoch</span>
</span><span data-line="52">        <span class="c1"># so that we can maximize the batch size quickly on a GPU</span>
</span><span data-line="53">        <span class="c1"># by the success of first several training steps</span>
</span><span data-line="54">        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span></div>

</span><span data-line="55">
<div class="viewcode-block" id="PLModel.on_train_epoch_end">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel.on_train_epoch_end">[docs]</a>
</span><span data-line="56">    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span data-line="57">        <span class="c1"># instead of checking it after every training step, which is costly</span>
</span><span data-line="58">        <span class="n">detect_nan_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span></div>

</span><span data-line="59">
<div class="viewcode-block" id="PLModel.on_validation_epoch_end">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel.on_validation_epoch_end">[docs]</a>
</span><span data-line="60">    <span class="k">def</span><span class="w"> </span><span class="nf">on_validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span data-line="61">        <span class="c1"># we calculate the epochal validation loss that is compatible with</span>
</span><span data-line="62">        <span class="c1"># the original loss calculation for combined metasets (which is still used for training)</span>
</span><span data-line="63">        <span class="c1"># i.e., a weighted mean with batch size for each metaset as weight</span>
</span><span data-line="64">        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span data-line="65">            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
</span><span data-line="66">                <span class="bp">self</span><span class="o">.</span><span class="n">validation_step_outputs</span><span class="p">,</span>
</span><span data-line="67">                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span data-line="68">            <span class="p">)</span>  <span class="c1"># shape (N_metasets, N_batches, 2)</span>
</span><span data-line="69">            <span class="c1"># if metasets are not used, or if just one metaset is used,</span>
</span><span data-line="70">            <span class="c1"># adjust the shape accordingly:</span>
</span><span data-line="71">            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
</span><span data-line="72">                <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span data-line="73">            <span class="n">out</span> <span class="o">=</span> <span class="p">(</span>
</span><span data-line="74">                <span class="n">out</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
</span><span data-line="75">                <span class="o">*</span> <span class="n">out</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>
</span><span data-line="76">                <span class="o">/</span> <span class="n">out</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="77">            <span class="p">)</span>
</span><span data-line="78">            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># shape (N_batches,)</span>
</span><span data-line="79">            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="80">        <span class="c1"># in ddp this will be run separately on different processes</span>
</span><span data-line="81">        <span class="c1"># therefore we need to synchronize (sync_dist=True)</span>
</span><span data-line="82">        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
</span><span data-line="83">            <span class="s2">&quot;validation_loss&quot;</span><span class="p">,</span>
</span><span data-line="84">            <span class="n">out</span><span class="p">,</span>
</span><span data-line="85">            <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span data-line="86">            <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="87">            <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="88">            <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="89">            <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="90">        <span class="p">)</span>
</span><span data-line="91">        <span class="bp">self</span><span class="o">.</span><span class="n">validation_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span></div>

</span><span data-line="92">
<div class="viewcode-block" id="PLModel.training_step">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel.training_step">[docs]</a>
</span><span data-line="93">    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">AtomicData</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="94">        <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
</span><span data-line="95">        <span class="k">return</span> <span class="n">loss</span></div>

</span><span data-line="96">
<div class="viewcode-block" id="PLModel.validation_step">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel.validation_step">[docs]</a>
</span><span data-line="97">    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span>
</span><span data-line="98">        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">AtomicData</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span>
</span><span data-line="99">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
</span><span data-line="100"><span class="w">        </span><span class="sd">&quot;&quot;&quot;The order of separate validation losses (bearing the name `dataloader_idx_?`) will</span>
</span><span data-line="101"><span class="sd">        be alphabetically ascending with respect to the Metaset names in the multi-metaset scenario.</span>
</span><span data-line="102"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="103">        <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">)</span>
</span><span data-line="104">        <span class="bp">self</span><span class="o">.</span><span class="n">validation_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">))</span>
</span><span data-line="105">        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span></div>

</span><span data-line="106">
<div class="viewcode-block" id="PLModel.test_step">
<a class="viewcode-back" href="../../../training.html#mlcg.pl.PLModel.test_step">[docs]</a>
</span><span data-line="107">    <span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span>
</span><span data-line="108">        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">AtomicData</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span>
</span><span data-line="109">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
</span><span data-line="110">        <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">)</span>
</span><span data-line="111">        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span></div>

</span><span data-line="112">
</span><span data-line="113">    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">AtomicData</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
</span><span data-line="114">        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">stage</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">derivative</span><span class="p">):</span>
</span><span data-line="115">            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span data-line="116">        <span class="n">data</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="o">.</span><span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>
</span><span data-line="117">        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span data-line="118">        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">N_ATOMS_KEY</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span data-line="119">        <span class="c1"># Add sync_dist=True to sync logging across all GPU workers</span>
</span><span data-line="120">        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
</span><span data-line="121">            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">stage</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">,</span>
</span><span data-line="122">            <span class="n">loss</span><span class="p">,</span>
</span><span data-line="123">            <span class="n">on_step</span><span class="o">=</span><span class="p">(</span><span class="n">stage</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">),</span>
</span><span data-line="124">            <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="125">            <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="126">            <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="127">            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span><span data-line="128">            <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="129">        <span class="p">)</span>
</span><span data-line="130">
</span><span data-line="131">        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batch_size</span>
</span><span data-line="132">
</span><span data-line="133">    <span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span><span data-line="134">        <span class="k">return</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span></div>

</span></pre></div>
        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2026, Clementi Group</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../../_static/documentation_options.js?v=92734c54"></script>
      <script src="../../../_static/doctools.js?v=fd6eb6e6"></script>
      <script src="../../../_static/sphinx_highlight.js?v=6ffebe34"></script>
      <script src="../../../_static/shibuya.js?v=cac61aee"></script></body>
</html>